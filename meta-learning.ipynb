{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implementation of Contrastive Loss.\n",
    "\n",
    "Users are free to copy and distribute only with citation.\n",
    "\n",
    "https://github.com/ShravanAnandk7/Keras-Image-Embeddings-using-Contrastive-Loss\n",
    "\n",
    "Last updated 09 Jan 2022\n",
    "\n",
    "TODO: \n",
    "\n",
    "      1) Add cosine distance metric\n",
    "\n",
    "      2) Add Batch-Hard and Semi-Hard triplet generation\n",
    "\n",
    "      3) Resize with padding in pre-processing pipe\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from cv2 import cv2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import itertools\n",
    "import tensorflow.keras.utils as KU\n",
    "import tensorflow.keras.layers as KL\n",
    "import tensorflow.keras.models as KM\n",
    "import tensorflow.keras.losses as KLo\n",
    "import tensorflow.keras.optimizers as KO\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.layers.pooling import GlobalAveragePooling2D\n",
    "from imgaug import augmenters as arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR    = os.getcwd() #os.path.dirname(__file__)\n",
    "os.chdir(BASE_DIR)\n",
    "MODEL_DIR       =  os.path.join(BASE_DIR,\"models\")\n",
    "DATASET_DIR     =  os.path.join(BASE_DIR,\"datasets\")\n",
    "BATCH_SIZE      =  10\n",
    "NUM_EPOCHS      =  2\n",
    "INPUT_SHAPE     =  299\n",
    "EMBEDDING_SIZE  =  32\n",
    "LOSS_MARGIN     =  0.4\n",
    "HUBER_DELTA     =  0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image augmenter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION      = arg.Sequential(\n",
    "\n",
    "                            [       \n",
    "                                arg.OneOf([arg.Fliplr(0.5), arg.Flipud(0.5)]),\n",
    "                                arg.Affine(scale = (0.85, 1.05),name=\"scale\"),\n",
    "                                arg.Rotate(rotate = (-10,10),name = \"1a2_rotate_1\"),\n",
    "                                arg.TranslateX(percent = (-0.05, 0.05), name= \"1a3_translatex_1\"),\n",
    "                                arg.TranslateY(percent = (-0.05, 0.05), name= \"1a4_translatey_1\"),\n",
    "                                arg.OneOf([\n",
    "                                        arg.Sometimes(0.9,arg.MultiplyAndAddToBrightness(mul=(0.70, 1.30), add=(-5, 5)),name=\"2a1_MulAddBrightness\"),\n",
    "                                        arg.MultiplySaturation(mul=(0.95,1.05),name=\"2b3_MulSat\"),\n",
    "                                        arg.MultiplyAndAddToBrightness(mul=(1,1.5), add=(-10,10),name=\"2b4_MulAddBrightness\")\n",
    "                                            ]),\n",
    "                                arg.Sometimes(0.2,arg.GaussianBlur(sigma = (0.0, 1.5)),name=\"3a1_gaussian_blur_0.2\")\n",
    "                            ]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datagenerator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotTripletDataGen(KU.Sequence):\n",
    "    def __init__(self,path,image_dim, batch_size = 1, shuffle = True,\n",
    "                 augmenter = None):\n",
    "        self.image_dim  = image_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.augmenter  = augmenter\n",
    "         \n",
    "        categories = os.listdir(path)\n",
    "        folder_paths = list(map(partial(os.path.join,path),categories))\n",
    "        images = list(map(os.listdir, folder_paths))\n",
    "        self.dataframe = pd.DataFrame(\n",
    "                                {\n",
    "                                    \"categories\" :categories,\n",
    "                                    \"folder path\" : folder_paths,\n",
    "                                    \"images\": images,\n",
    "                                    \"number\": len(images)\n",
    "                                })\n",
    "        # print(self.dataframe)\n",
    "        print(\"Categories found\",self.dataframe.__len__())\n",
    "        self.duplets  = list(itertools.permutations(np.arange(len(self.dataframe)),2))\n",
    "        self.triplets = [((x,a),(x,b),(y,c)) for x,y in self.duplets \n",
    "        for a,b,c in list(itertools.product(np.arange(self.dataframe.loc[x][\"number\"]),\n",
    "        np.arange(self.dataframe.loc[x][\"number\"]),\n",
    "        np.arange(self.dataframe.loc[y][\"number\"]))) if (x,a) != (x,b)]\n",
    "        # print(list(itertools.permutations(np.arange(self.dataframe.loc[0][\"number\"]),2)))\n",
    "        print(len(self.triplets))\n",
    "        self.on_epoch_end()\n",
    "        print(\"Total triplets : \",len(self.triplets))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.triplets) / self.batch_size))\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.triplets))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Outputs = [Anchor, Positive, Negative] with \n",
    "        shape (Batch, 3, Height, Width, 3)\n",
    "        \"\"\"\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)\n",
    "                        *self.batch_size]\n",
    "        X, y = self.__batch_all_triplet_data_gen(batch_indexes) \n",
    "        return X, y\n",
    "    def __batch_all_triplet_data_gen(self,batch_indexes):\n",
    "        X=[]\n",
    "        anchor_list = []\n",
    "        positive_list = []\n",
    "        negative_list = []\n",
    "        # print(\"batch Indices : \", batch_indexes)\n",
    "        for row_id in batch_indexes:\n",
    "            anchor   = os.path.join(self.dataframe.loc[self.triplets[row_id][0][0]][\"folder path\"],self.dataframe.loc[self.triplets[row_id][0][0]][\"images\"][self.triplets[row_id][0][1]])\n",
    "            positive = os.path.join(self.dataframe.loc[self.triplets[row_id][1][0]][\"folder path\"],self.dataframe.loc[self.triplets[row_id][1][0]][\"images\"][self.triplets[row_id][1][1]])\n",
    "            negative = os.path.join(self.dataframe.loc[self.triplets[row_id][2][0]][\"folder path\"],self.dataframe.loc[self.triplets[row_id][2][0]][\"images\"][self.triplets[row_id][2][1]])\n",
    "            # print(anchor,'\\n',positive,'\\n',negative)\n",
    "\n",
    "            anchor = self.pre_process(self.__augmenter(cv2.imread(anchor)))\n",
    "            positive = self.pre_process(self.__augmenter(cv2.imread(positive)))\n",
    "            negative = self.pre_process(self.__augmenter(cv2.imread(negative)))\n",
    "            # # print(anchor.shape, positive.shape, negative.shape)\n",
    "            anchor_list.append(anchor)\n",
    "            positive_list.append(positive)\n",
    "            negative_list.append(negative)\n",
    "        return (np.asarray(anchor_list),np.asarray(positive_list),np.array(negative_list)), None\n",
    "    def pre_process(self,image):\n",
    "        \"\"\" \n",
    "        Model specific image preprocessing function\n",
    "        TODO: Resize with crop and padding\n",
    "        \"\"\"\n",
    "        image = cv2.resize(image,self.image_dim)\n",
    "        image = image/127.5 -1\n",
    "        return image\n",
    "    def __augmenter(self,image):\n",
    "        if self.augmenter is not None:      \n",
    "            image_shape = image.shape\n",
    "            image = self.augmenter.augment_image(image)\n",
    "            #Augmentation shouldn't change image size\n",
    "            assert image.shape == image_shape\n",
    "        return image\n",
    "# train_gen = FewShotTripletDataGen(path = os.path.join(\n",
    "#              DATASET_DIR,\"few-shot-dataset\",\"train\"),\n",
    "#              image_dim=(INPUT_SHAPE,INPUT_SHAPE), \n",
    "#              batch_size=BATCH_SIZE,augmenter=AUGMENTATION)\n",
    "# train_gen[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom loss layer for implementation of contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(KL.Layer):\n",
    "    def __init__(self,margin=1,delta=1,**kwargs):\n",
    "        self.margin = margin\n",
    "        self.huber_delta = delta\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "        pass\n",
    "    def euclidean_distance(self,x,y):\n",
    "        \"\"\"\n",
    "        Euclidean distance metric\n",
    "        \"\"\"\n",
    "        return K.sum(K.square(x-y), axis=-1)\n",
    "    def cosine_distance(self,x,y):\n",
    "        \"\"\"\n",
    "        Cosine distance metric\n",
    "        \"\"\"\n",
    "        pass\n",
    "    def triplet_loss(self, inputs):\n",
    "        anchor, positive, negative = inputs\n",
    "        p_dist = self.euclidean_distance(anchor[0],positive[0])\n",
    "        n_dist = self.euclidean_distance(anchor[0],negative[0])\n",
    "        t_loss  = K.maximum(p_dist - n_dist + self.margin, 0)\n",
    "        # Huber loss\n",
    "        L1_loss = K.switch(t_loss < self.huber_delta, 0.5 * t_loss ** 2, self.huber_delta * (t_loss - 0.5 * self.huber_delta))\n",
    "        return K.sum(L1_loss)\n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the base network keras model to generate embeddings,\n",
    "Replace the base_model function with your custom model arcitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 297, 297, 8)       224       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 297, 297, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 297, 148, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 295, 146, 16)      1168      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 295, 146, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 147, 146, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 147, 146, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 145, 144, 32)      4640      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 145, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 145, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "=================================================================\n",
      "Total params: 7,152\n",
      "Trainable params: 7,120\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def base_network():\n",
    "    \"\"\"\n",
    "    Base CNN model trained for embedding extraction\n",
    "    \"\"\"\n",
    "    return( \n",
    "            KM.Sequential(\n",
    "                [   \n",
    "                    KL.Input(shape=(INPUT_SHAPE,INPUT_SHAPE,3)),\n",
    "                    KL.Conv2D(8,(3,3)),\n",
    "                    KL.ReLU(),\n",
    "                    KL.MaxPool2D(pool_size=(1,2)),\n",
    "                    # KL.BatchNormalization(),\n",
    "                    KL.Conv2D(16,(3,3)),\n",
    "                    KL.ReLU(),\n",
    "                    KL.MaxPool2D(pool_size=(2,1)),\n",
    "                    KL.BatchNormalization(),\n",
    "                    KL.Conv2D(32,(3,3)),\n",
    "                    KL.ReLU(),\n",
    "                    KL.MaxPool2D(pool_size=(1,1)),\n",
    "                    KL.GlobalAveragePooling2D(),\n",
    "                    # Don't Change the below layers\n",
    "                    KL.Dense(EMBEDDING_SIZE,activation = 'relu'),\n",
    "                    # KL.Lambda(lambda x: K.l2_normalize(x,axis=-1))\n",
    "                ]))\n",
    "base = base_network()\n",
    "print(base.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.load_weights(os.path.join(BASE_DIR, \"models\",\"few-shot.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_network(base):\n",
    "    Anchor   = KL.Input(shape=(INPUT_SHAPE,INPUT_SHAPE,3),name= \"anchor_input\")\n",
    "    Positive = KL.Input(shape=(INPUT_SHAPE,INPUT_SHAPE,3),name= \"positive_input\")\n",
    "    Negative = KL.Input(shape=(INPUT_SHAPE,INPUT_SHAPE,3),name= \"negative_input\")\n",
    "\n",
    "    Anchor_Emb = base(Anchor)\n",
    "    Positive_Emb = base(Positive)\n",
    "    Negative_Emb = base(Negative)\n",
    "    \n",
    "    loss = TripletLossLayer(LOSS_MARGIN,HUBER_DELTA)([Anchor_Emb,Positive_Emb,Negative_Emb])\n",
    "    model = KM.Model(inputs = [Anchor,Positive,Negative], outputs=loss)\n",
    "    return model\n",
    "triplet_model = triplet_network(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model and save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data :\n",
      "Categories found 9\n",
      "52488\n",
      "Total triplets :  52488\n",
      "Test Data :\n",
      "Categories found 10\n",
      "90000\n",
      "Total triplets :  90000\n",
      "Epoch 1/2\n",
      "  63/5248 [..............................] - ETA: 4:22:54 - loss: 0.0876"
     ]
    }
   ],
   "source": [
    "optimizer = KO.Adam(lr = 0.001)\n",
    "triplet_model.compile(loss=None,optimizer=optimizer)\n",
    "print(\"Train Data :\")\n",
    "train_gen = FewShotTripletDataGen(path = os.path.join(\n",
    "             DATASET_DIR,\"few-shot-dataset\",\"train\"),\n",
    "             image_dim=(INPUT_SHAPE,INPUT_SHAPE), \n",
    "             batch_size=BATCH_SIZE,augmenter=AUGMENTATION)\n",
    "print(\"Test Data :\")\n",
    "\n",
    "valid_gen = FewShotTripletDataGen(path = os.path.join(\n",
    "             DATASET_DIR,\"few-shot-dataset\",\"test\"),\n",
    "             image_dim=(INPUT_SHAPE,INPUT_SHAPE), \n",
    "             batch_size=BATCH_SIZE)\n",
    "triplet_model.fit(x=train_gen,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  validation_data=valid_gen,\n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  workers=1)\n",
    "# Save trained model weights\n",
    "base.save_weights(os.path.join(BASE_DIR, \"models\",\"few-shot.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\06 Development\\05 Git Reps\\Keras-Image-Embeddings-using-Contrastive-Loss\\datasets\\few-shot-dataset\\test\\cat\\0013.jpg\n",
      "[[0.25258532 0.10275707 0.         0.19828758 0.03829682 0.19903469\n",
      "  0.         0.08477098 0.         0.17425714 0.         0.\n",
      "  0.         0.16769291 0.         0.         0.         0.1337439\n",
      "  0.         0.         0.         0.         0.         0.31681383\n",
      "  0.         0.28377467 0.         0.         0.10693571 0.\n",
      "  0.         0.0271601 ]]\n"
     ]
    }
   ],
   "source": [
    "image_path = os.path.join(\n",
    "             DATASET_DIR,\"few-shot-dataset\",\"test\",\"cat\",\"0013.jpg\")\n",
    "print(image_path)\n",
    "input = train_gen.pre_process(cv2.imread(image_path))\n",
    "output_embeddings = base.predict(np.expand_dims(input,axis=0))\n",
    "print(output_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
